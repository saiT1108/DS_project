{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severity of storms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our project will focus on analyzing and predicting the severity of tornadoes across various regions in America in terms of property damage. To analyze this, we will take the last 10 years of tornado data to represent an approximate measure of it. To calculate this, we will establish a threshold for measuring the severity using the amount of property damage caused by tornadoes. We will predict the property damage of tornadoes and use a scale of low, medium, and high to represent the severity.  \n",
    "In addition, we will also compare attitudes across each of the 4 seasons - summer, spring, winter, fall, and see if there are any trends present across the 10 year span that shows when tornadoes are most common and damaging. The trends will help us be more accurate in predicting the property damage caused by the tornadoes per region during different seasons/times of the year. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our dataset details instances of severe weather across a 10 year period. The dataset shows us the date/year, the state the tornado occured in, deaths/injuries, and the property damage. We will be using this dataset to predict the property damage caused by future tornadoes in region acros the US. Bonus: We will predict deaths/injuries if we have more time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Proposed analytics solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " How we get to the target variable -- severity index\n",
    "The severity index will be calculated byâ€¦ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Read all data into one single dataframe\n",
    "df_all_data = pd.read_csv('./dataset/storm_event_details_2010.csv')\n",
    "\n",
    "for i in range(2011,2021):\n",
    "    df_temp = pd.read_csv(f'./dataset/storm_event_details_{i}.csv')\n",
    "    df_all_data = df_all_data.append(df_temp, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3721/2689778143.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n"
     ]
    }
   ],
   "source": [
    "## Remove unused columns and format continuous columns\n",
    "\n",
    "df_hur = df_all_data[df_all_data['EVENT_TYPE']=='Tornado']\n",
    "df_hur = df_hur.drop(columns=['TOR_OTHER_WFO', 'END_YEARMONTH', 'EVENT_TYPE', 'END_DATE_TIME', 'BEGIN_YEARMONTH', 'BEGIN_DAY', \n",
    "                                            'END_DAY', 'EPISODE_ID', 'EVENT_ID',\n",
    "                                           'TOR_OTHER_CZ_STATE','TOR_OTHER_CZ_FIPS','TOR_OTHER_CZ_NAME','DATA_SOURCE','EPISODE_NARRATIVE',\n",
    "                                            'EVENT_NARRATIVE','WFO','SOURCE','CZ_TIMEZONE','BEGIN_AZIMUTH','END_AZIMUTH','BEGIN_LAT',\n",
    "                                            'END_LAT','BEGIN_LON','END_LON','STATE_FIPS','BEGIN_RANGE','END_RANGE','DAMAGE_CROPS',\n",
    "                                            'BEGIN_TIME','END_TIME','BEGIN_LOCATION','END_LOCATION','FLOOD_CAUSE','MAGNITUDE_TYPE',\n",
    "                                            'MAGNITUDE','CZ_FIPS','CZ_TYPE','CZ_NAME','CATEGORY'])\n",
    "cols = ['INJURIES_INDIRECT', 'INJURIES_DIRECT', 'DEATHS_INDIRECT', 'DEATHS_DIRECT']\n",
    "df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n",
    "df_hur['TOR_AREA'] = df_hur['TOR_LENGTH']*df_hur['TOR_WIDTH']\n",
    "df_hur = df_hur.drop(columns=['TOR_LENGTH', 'TOR_WIDTH'])\n",
    "df_dqr = df_hur.copy()\n",
    "df_hur = df_hur.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAMAGE_PROPERTY\n",
      "75               5.00K\n",
      "304              1.50M\n",
      "617             10.00K\n",
      "731            750.00K\n",
      "732             10.00K\n",
      "...                ...\n",
      "688471           0.00K\n",
      "688472         250.00K\n",
      "688495          60.00K\n",
      "688497           0.00K\n",
      "688560           0.00K\n",
      "\n",
      "[12945 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## Format DAMAGE_PROPERTY column to be float instead of object\n",
    "\n",
    "dmg = pd.DataFrame(df_hur['DAMAGE_PROPERTY'])\n",
    "\n",
    "print(dmg)\n",
    "for index, row in dmg.iterrows():\n",
    "    val = row['DAMAGE_PROPERTY']\n",
    "    if val[-1:] == 'B':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000000\n",
    "    elif val[-1:] == 'M':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000\n",
    "    elif val[-1:] == 'K':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000\n",
    "\n",
    "df_hur['DAMAGE_PROPERTY'] = dmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12945 entries, 100619 to 688560\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   STATE            12945 non-null  object \n",
      " 1   YEAR             12945 non-null  int64  \n",
      " 2   MONTH_NAME       12945 non-null  object \n",
      " 3   BEGIN_DATE_TIME  12945 non-null  object \n",
      " 4   DAMAGE_PROPERTY  12945 non-null  object \n",
      " 5   TOR_F_SCALE      12945 non-null  object \n",
      " 6   HARM_TOTAL       12945 non-null  int64  \n",
      " 7   TOR_AREA         12945 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 910.2+ KB\n",
      "EF0    51.117296\n",
      "EF1    35.737575\n",
      "EF2     9.852883\n",
      "EF3     2.576541\n",
      "EF4     0.628231\n",
      "EF5     0.087475\n",
      "Name: TOR_F_SCALE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Sort by priority variable and find data split percentages\n",
    "\n",
    "df_hur = df_hur.sort_values('DAMAGE_PROPERTY', ascending=False)\n",
    "df_hur.info()\n",
    "df_hur = df_hur.loc[df_hur['TOR_F_SCALE']!='EFU']\n",
    "print(df_hur['TOR_F_SCALE'].value_counts()/len(df_hur) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "April        21.677932\n",
       "May          20.548708\n",
       "June         12.413519\n",
       "July          7.093439\n",
       "March         6.727634\n",
       "August        6.067594\n",
       "October       5.137177\n",
       "November      4.580517\n",
       "January       4.413519\n",
       "February      4.159046\n",
       "September     3.618290\n",
       "December      3.562624\n",
       "Name: MONTH_NAME, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hur['MONTH_NAME'].value_counts()/len(df_hur) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>BEGIN_DATE_TIME</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>HARM_TOTAL</th>\n",
       "      <th>TOR_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611048</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2019</td>\n",
       "      <td>May</td>\n",
       "      <td>20-MAY-19 09:50:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541633</th>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>2018</td>\n",
       "      <td>June</td>\n",
       "      <td>26-JUN-18 17:53:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91202</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>25-APR-11 14:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221142</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2013</td>\n",
       "      <td>December</td>\n",
       "      <td>20-DEC-13 18:33:00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265932</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2013</td>\n",
       "      <td>May</td>\n",
       "      <td>15-MAY-13 19:34:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112277</th>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 18:33:00</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>0</td>\n",
       "      <td>16830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331518</th>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>2015</td>\n",
       "      <td>April</td>\n",
       "      <td>09-APR-15 17:43:00</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>0</td>\n",
       "      <td>14658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35891</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2010</td>\n",
       "      <td>April</td>\n",
       "      <td>24-APR-10 11:33:00</td>\n",
       "      <td>60000000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>41</td>\n",
       "      <td>55250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661920</th>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>2020</td>\n",
       "      <td>July</td>\n",
       "      <td>08-JUL-20 16:15:00</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>3</td>\n",
       "      <td>4225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137505</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 13:30:00</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>EF5</td>\n",
       "      <td>0</td>\n",
       "      <td>11997.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              STATE  YEAR MONTH_NAME     BEGIN_DATE_TIME DAMAGE_PROPERTY  \\\n",
       "611048      ARIZONA  2019        May  20-MAY-19 09:50:00             0.0   \n",
       "541633     ILLINOIS  2018       June  26-JUN-18 17:53:00             0.0   \n",
       "91202         TEXAS  2011      April  25-APR-11 14:10:00             0.0   \n",
       "221142     ARKANSAS  2013   December  20-DEC-13 18:33:00        100000.0   \n",
       "265932        TEXAS  2013        May  15-MAY-13 19:34:00             0.0   \n",
       "...             ...   ...        ...                 ...             ...   \n",
       "112277    TENNESSEE  2011      April  27-APR-11 18:33:00       1000000.0   \n",
       "331518     ILLINOIS  2015      April  09-APR-15 17:43:00      10000000.0   \n",
       "35891   MISSISSIPPI  2010      April  24-APR-10 11:33:00      60000000.0   \n",
       "661920    MINNESOTA  2020       July  08-JUL-20 16:15:00       1500000.0   \n",
       "137505  MISSISSIPPI  2011      April  27-APR-11 13:30:00        500000.0   \n",
       "\n",
       "       TOR_F_SCALE  HARM_TOTAL  TOR_AREA  \n",
       "611048         EF0           0      10.0  \n",
       "541633         EF0           0       2.5  \n",
       "91202          EF0           0    1028.0  \n",
       "221142         EF0           0     222.0  \n",
       "265932         EF0           0       6.3  \n",
       "...            ...         ...       ...  \n",
       "112277         EF4           0   16830.0  \n",
       "331518         EF4           0   14658.0  \n",
       "35891          EF4          41   55250.0  \n",
       "661920         EF4           3    4225.0  \n",
       "137505         EF5           0   11997.0  \n",
       "\n",
       "[1257 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split data into strata and sample proportinally (stratified sampling)\n",
    "\n",
    "sampled_df = df_hur.groupby('TOR_F_SCALE', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "      <th>Count</th>\n",
       "      <th>% Missing</th>\n",
       "      <th>Cardinality</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mode Frequency</th>\n",
       "      <th>Mode %</th>\n",
       "      <th>2nd Mode</th>\n",
       "      <th>2nd Mode Frequency</th>\n",
       "      <th>2nd Mode %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATE</td>\n",
       "      <td>State where tornado touched down</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1359</td>\n",
       "      <td>9.07</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>1012</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YEAR</td>\n",
       "      <td>Year of occurence</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>2074</td>\n",
       "      <td>13.84</td>\n",
       "      <td>2019</td>\n",
       "      <td>1732</td>\n",
       "      <td>11.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONTH_NAME</td>\n",
       "      <td>Month of occurence</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>May</td>\n",
       "      <td>3181</td>\n",
       "      <td>21.22</td>\n",
       "      <td>April</td>\n",
       "      <td>3122</td>\n",
       "      <td>20.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOR_F_SCALE</td>\n",
       "      <td>Fujita Scale for intensity of tornado</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>EF0</td>\n",
       "      <td>7379</td>\n",
       "      <td>49.23</td>\n",
       "      <td>EF1</td>\n",
       "      <td>5263</td>\n",
       "      <td>35.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature                            Description  Count % Missing  \\\n",
       "0        STATE       State where tornado touched down  14988       0.0   \n",
       "1         YEAR                      Year of occurence  14988       0.0   \n",
       "2   MONTH_NAME                     Month of occurence  14988       0.0   \n",
       "3  TOR_F_SCALE  Fujita Scale for intensity of tornado  14988       0.0   \n",
       "\n",
       "  Cardinality   Mode Mode Frequency Mode %  2nd Mode 2nd Mode Frequency  \\\n",
       "0          52  TEXAS           1359   9.07  OKLAHOMA               1012   \n",
       "1          11   2011           2074  13.84      2019               1732   \n",
       "2          12    May           3181  21.22     April               3122   \n",
       "3           7    EF0           7379  49.23       EF1               5263   \n",
       "\n",
       "  2nd Mode %  \n",
       "0       6.75  \n",
       "1      11.56  \n",
       "2      20.83  \n",
       "3      35.11  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DQR for categorical variables\n",
    "\n",
    "cat_cols = ['STATE', 'YEAR', 'MONTH_NAME', 'TOR_F_SCALE']\n",
    "cat_df = df_dqr[cat_cols]\n",
    "cat_df\n",
    "\n",
    "dqr_cat = pd.DataFrame(columns=['Feature', 'Description', 'Count', '% Missing', 'Cardinality','Mode',\n",
    "'Mode Frequency', 'Mode %', '2nd Mode', '2nd Mode Frequency', '2nd Mode %'])\n",
    "\n",
    "descs = ['State where tornado touched down', 'Year of occurence', 'Month of occurence', 'Fujita Scale for intensity of tornado']\n",
    "\n",
    "dqr_cat['Feature'] = cat_cols\n",
    "\n",
    "for index, row in dqr_cat.iterrows():\n",
    "    row['Description'] = descs[index]\n",
    "    row['Count'] = df_dqr[row['Feature']].count()\n",
    "    row['Cardinality'] = len(df_dqr[row['Feature']].unique())\n",
    "    row['Mode'] = df_dqr[row['Feature']].mode()[0]\n",
    "    row['% Missing'] = round((len(df_dqr[df_dqr[row['Feature']]=='?'])/row['Count'])*100, 2)\n",
    "    row['Mode Frequency'] = len(df_dqr[df_dqr[row['Feature']]==row['Mode']])\n",
    "    row['Mode %'] = round(row['Mode Frequency']/row['Count']*100, 2)\n",
    "    mode_df = df_dqr[df_dqr[row['Feature']]!=row['Mode']]\n",
    "    row['2nd Mode'] = mode_df[row['Feature']].mode()[0]\n",
    "    row['2nd Mode Frequency'] = len(mode_df[mode_df[row['Feature']]==row['2nd Mode']])\n",
    "    row['2nd Mode %'] = round(row['2nd Mode Frequency']/row['Count']*100, 2)\n",
    "\n",
    "dqr_cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
