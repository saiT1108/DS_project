{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severity of storms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our project will focus on analyzing and predicting the severity of tornadoes across various regions in America in terms of property damage. To analyze this, we will take the last 10 years of tornado data to represent an approximate measure of it. To calculate this, we will establish a threshold for measuring the severity using the amount of property damage caused by tornadoes. We will predict the property damage of tornadoes and use a scale of low, medium, and high to represent the severity.  \n",
    "In addition, we will also compare attitudes across each of the 4 seasons - summer, spring, winter, fall, and see if there are any trends present across the 10 year span that shows when tornadoes are most common and damaging. The trends will help us be more accurate in predicting the property damage caused by the tornadoes per region during different seasons/times of the year. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our dataset details instances of severe weather across a 10 year period. The dataset shows us the date/year, the state the tornado occured in, deaths/injuries, and the property damage. We will be using this dataset to predict the property damage caused by future tornadoes in region acros the US. Bonus: We will predict deaths/injuries if we have more time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Proposed analytics solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " How we get to the target variable -- severity index\n",
    "The severity index will be calculated byâ€¦ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Read all data into one single dataframe\n",
    "df_all_data = pd.read_csv('./dataset/storm_event_details_2010.csv')\n",
    "\n",
    "for i in range(2011,2021):\n",
    "    df_temp = pd.read_csv(f'./dataset/storm_event_details_{i}.csv')\n",
    "    df_all_data = df_all_data.append(df_temp, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3721/4266470316.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14988 entries, 75 to 688592\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   STATE            14988 non-null  object \n",
      " 1   YEAR             14988 non-null  int64  \n",
      " 2   MONTH_NAME       14988 non-null  object \n",
      " 3   BEGIN_DATE_TIME  14988 non-null  object \n",
      " 4   DAMAGE_PROPERTY  12945 non-null  object \n",
      " 5   TOR_F_SCALE      14988 non-null  object \n",
      " 6   HARM_TOTAL       14988 non-null  int64  \n",
      " 7   TOR_AREA         14988 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "## Remove unused columns and format continuous columns\n",
    "\n",
    "df_hur = df_all_data[df_all_data['EVENT_TYPE']=='Tornado']\n",
    "df_hur = df_hur.drop(columns=['TOR_OTHER_WFO', 'END_YEARMONTH', 'EVENT_TYPE', 'END_DATE_TIME', 'BEGIN_YEARMONTH', 'BEGIN_DAY', \n",
    "                                            'END_DAY', 'EPISODE_ID', 'EVENT_ID',\n",
    "                                           'TOR_OTHER_CZ_STATE','TOR_OTHER_CZ_FIPS','TOR_OTHER_CZ_NAME','DATA_SOURCE','EPISODE_NARRATIVE',\n",
    "                                            'EVENT_NARRATIVE','WFO','SOURCE','CZ_TIMEZONE','BEGIN_AZIMUTH','END_AZIMUTH','BEGIN_LAT',\n",
    "                                            'END_LAT','BEGIN_LON','END_LON','STATE_FIPS','BEGIN_RANGE','END_RANGE','DAMAGE_CROPS',\n",
    "                                            'BEGIN_TIME','END_TIME','BEGIN_LOCATION','END_LOCATION','FLOOD_CAUSE','MAGNITUDE_TYPE',\n",
    "                                            'MAGNITUDE','CZ_FIPS','CZ_TYPE','CZ_NAME','CATEGORY'])\n",
    "cols = ['INJURIES_INDIRECT', 'INJURIES_DIRECT', 'DEATHS_INDIRECT', 'DEATHS_DIRECT']\n",
    "df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n",
    "df_hur['TOR_AREA'] = df_hur['TOR_LENGTH']*df_hur['TOR_WIDTH']\n",
    "df_hur = df_hur.drop(columns=['TOR_LENGTH', 'TOR_WIDTH'])\n",
    "\n",
    "dmg = pd.DataFrame(df_hur['DAMAGE_PROPERTY'])\n",
    "for index, row in dmg.iterrows():\n",
    "    if type(row['DAMAGE_PROPERTY']) != type(0.0):\n",
    "        val = row['DAMAGE_PROPERTY']\n",
    "        if val[-1:] == 'B':\n",
    "            row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000000\n",
    "        elif val[-1:] == 'M':\n",
    "            row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000\n",
    "        elif val[-1:] == 'K':\n",
    "            row['DAMAGE_PROPERTY'] = float(val[:-1])*1000\n",
    "\n",
    "df_hur['DAMAGE_PROPERTY'] = dmg\n",
    "\n",
    "df_dqr = df_hur.copy()\n",
    "df_hur = df_hur.dropna()\n",
    "\n",
    "df_dqr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format DAMAGE_PROPERTY column to be float instead of object\n",
    "\n",
    "# dmg = pd.DataFrame(df_hur['DAMAGE_PROPERTY'])\n",
    "\n",
    "# print(dmg)\n",
    "# for index, row in dmg.iterrows():\n",
    "#     val = row['DAMAGE_PROPERTY']\n",
    "#     if val[-1:] == 'B':\n",
    "#         row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000000\n",
    "#     elif val[-1:] == 'M':\n",
    "#         row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000\n",
    "#     elif val[-1:] == 'K':\n",
    "#         row['DAMAGE_PROPERTY'] = float(val[:-1])*1000\n",
    "\n",
    "# df_hur['DAMAGE_PROPERTY'] = dmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12945 entries, 100619 to 688560\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   STATE            12945 non-null  object \n",
      " 1   YEAR             12945 non-null  int64  \n",
      " 2   MONTH_NAME       12945 non-null  object \n",
      " 3   BEGIN_DATE_TIME  12945 non-null  object \n",
      " 4   DAMAGE_PROPERTY  12945 non-null  object \n",
      " 5   TOR_F_SCALE      12945 non-null  object \n",
      " 6   HARM_TOTAL       12945 non-null  int64  \n",
      " 7   TOR_AREA         12945 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 910.2+ KB\n",
      "EF0    51.117296\n",
      "EF1    35.737575\n",
      "EF2     9.852883\n",
      "EF3     2.576541\n",
      "EF4     0.628231\n",
      "EF5     0.087475\n",
      "Name: TOR_F_SCALE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Sort by priority variable and find data split percentages\n",
    "\n",
    "df_hur = df_hur.sort_values('DAMAGE_PROPERTY', ascending=False)\n",
    "df_hur.info()\n",
    "df_hur = df_hur.loc[df_hur['TOR_F_SCALE']!='EFU']\n",
    "print(df_hur['TOR_F_SCALE'].value_counts()/len(df_hur) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "April        21.677932\n",
       "May          20.548708\n",
       "June         12.413519\n",
       "July          7.093439\n",
       "March         6.727634\n",
       "August        6.067594\n",
       "October       5.137177\n",
       "November      4.580517\n",
       "January       4.413519\n",
       "February      4.159046\n",
       "September     3.618290\n",
       "December      3.562624\n",
       "Name: MONTH_NAME, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hur['MONTH_NAME'].value_counts()/len(df_hur) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>BEGIN_DATE_TIME</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>HARM_TOTAL</th>\n",
       "      <th>TOR_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400687</th>\n",
       "      <td>IOWA</td>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>28-MAY-16 16:52:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50855</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2010</td>\n",
       "      <td>October</td>\n",
       "      <td>25-OCT-10 02:23:00</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462805</th>\n",
       "      <td>KANSAS</td>\n",
       "      <td>2017</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-17 16:21:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272903</th>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>2014</td>\n",
       "      <td>February</td>\n",
       "      <td>21-FEB-14 08:29:00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>666.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359947</th>\n",
       "      <td>OHIO</td>\n",
       "      <td>2015</td>\n",
       "      <td>April</td>\n",
       "      <td>19-APR-15 21:56:00</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244989</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2013</td>\n",
       "      <td>February</td>\n",
       "      <td>10-FEB-13 17:03:00</td>\n",
       "      <td>13500000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>8</td>\n",
       "      <td>9966.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96657</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 16:05:00</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>0</td>\n",
       "      <td>1944.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136287</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 16:35:00</td>\n",
       "      <td>700000000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>720</td>\n",
       "      <td>84578.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670878</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2020</td>\n",
       "      <td>April</td>\n",
       "      <td>12-APR-20 15:24:00</td>\n",
       "      <td>25900000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>5</td>\n",
       "      <td>60469.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126672</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 14:42:00</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>EF5</td>\n",
       "      <td>53</td>\n",
       "      <td>7986.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              STATE  YEAR MONTH_NAME     BEGIN_DATE_TIME DAMAGE_PROPERTY  \\\n",
       "400687         IOWA  2016        May  28-MAY-16 16:52:00             0.0   \n",
       "50855       ALABAMA  2010    October  25-OCT-10 02:23:00         35000.0   \n",
       "462805       KANSAS  2017      April  27-APR-17 16:21:00             0.0   \n",
       "272903      GEORGIA  2014   February  21-FEB-14 08:29:00        100000.0   \n",
       "359947         OHIO  2015      April  19-APR-15 21:56:00          5000.0   \n",
       "...             ...   ...        ...                 ...             ...   \n",
       "244989  MISSISSIPPI  2013   February  10-FEB-13 17:03:00      13500000.0   \n",
       "96657       ALABAMA  2011      April  27-APR-11 16:05:00      20000000.0   \n",
       "136287      ALABAMA  2011      April  27-APR-11 16:35:00     700000000.0   \n",
       "670878  MISSISSIPPI  2020      April  12-APR-20 15:24:00      25900000.0   \n",
       "126672  MISSISSIPPI  2011      April  27-APR-11 14:42:00       2500000.0   \n",
       "\n",
       "       TOR_F_SCALE  HARM_TOTAL  TOR_AREA  \n",
       "400687         EF0           0      2.25  \n",
       "50855          EF0           0     93.00  \n",
       "462805         EF0           0     74.00  \n",
       "272903         EF0           0    666.00  \n",
       "359947         EF0           0     64.50  \n",
       "...            ...         ...       ...  \n",
       "244989         EF4           8   9966.00  \n",
       "96657          EF4           0   1944.80  \n",
       "136287         EF4         720  84578.00  \n",
       "670878         EF4           5  60469.20  \n",
       "126672         EF5          53   7986.00  \n",
       "\n",
       "[1257 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split data into strata and sample proportinally (stratified sampling)\n",
    "\n",
    "sampled_df = df_hur.groupby('TOR_F_SCALE', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "      <th>Count</th>\n",
       "      <th>% Missing</th>\n",
       "      <th>Cardinality</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mode Frequency</th>\n",
       "      <th>Mode %</th>\n",
       "      <th>2nd Mode</th>\n",
       "      <th>2nd Mode Frequency</th>\n",
       "      <th>2nd Mode %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATE</td>\n",
       "      <td>State where tornado touched down</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1359</td>\n",
       "      <td>9.07</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>1012</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YEAR</td>\n",
       "      <td>Year of occurence</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>2074</td>\n",
       "      <td>13.84</td>\n",
       "      <td>2019</td>\n",
       "      <td>1732</td>\n",
       "      <td>11.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONTH_NAME</td>\n",
       "      <td>Month of occurence</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>May</td>\n",
       "      <td>3181</td>\n",
       "      <td>21.22</td>\n",
       "      <td>April</td>\n",
       "      <td>3122</td>\n",
       "      <td>20.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOR_F_SCALE</td>\n",
       "      <td>Fujita Scale for intensity of tornado</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>EF0</td>\n",
       "      <td>7379</td>\n",
       "      <td>49.23</td>\n",
       "      <td>EF1</td>\n",
       "      <td>5263</td>\n",
       "      <td>35.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature                            Description  Count % Missing  \\\n",
       "0        STATE       State where tornado touched down  14988       0.0   \n",
       "1         YEAR                      Year of occurence  14988       0.0   \n",
       "2   MONTH_NAME                     Month of occurence  14988       0.0   \n",
       "3  TOR_F_SCALE  Fujita Scale for intensity of tornado  14988       0.0   \n",
       "\n",
       "  Cardinality   Mode Mode Frequency Mode %  2nd Mode 2nd Mode Frequency  \\\n",
       "0          52  TEXAS           1359   9.07  OKLAHOMA               1012   \n",
       "1          11   2011           2074  13.84      2019               1732   \n",
       "2          12    May           3181  21.22     April               3122   \n",
       "3           7    EF0           7379  49.23       EF1               5263   \n",
       "\n",
       "  2nd Mode %  \n",
       "0       6.75  \n",
       "1      11.56  \n",
       "2      20.83  \n",
       "3      35.11  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DQR for categorical variables\n",
    "\n",
    "cat_cols = ['STATE', 'YEAR', 'MONTH_NAME', 'TOR_F_SCALE']\n",
    "cat_df = df_dqr[cat_cols]\n",
    "cat_df\n",
    "\n",
    "dqr_cat = pd.DataFrame(columns=['Feature', 'Description', 'Count', '% Missing', 'Cardinality','Mode',\n",
    "'Mode Frequency', 'Mode %', '2nd Mode', '2nd Mode Frequency', '2nd Mode %'])\n",
    "\n",
    "descs = ['State where tornado touched down', 'Year of occurence', 'Month of occurence', 'Fujita Scale for intensity of tornado']\n",
    "\n",
    "dqr_cat['Feature'] = cat_cols\n",
    "\n",
    "for index, row in dqr_cat.iterrows():\n",
    "    row['Description'] = descs[index]\n",
    "    row['Count'] = df_dqr[row['Feature']].count()\n",
    "    row['Cardinality'] = len(df_dqr[row['Feature']].unique())\n",
    "    row['Mode'] = df_dqr[row['Feature']].mode()[0]\n",
    "    if row['Feature'] == 'TOR_F_SCALE':\n",
    "        row['% Missing'] = round((len(df_dqr[df_dqr[row['Feature']]=='EFU'])/row['Count'])*100, 2)    \n",
    "    row['% Missing'] = round((len(df_dqr[df_dqr[row['Feature']]==None])/row['Count'])*100, 2)\n",
    "    row['Mode Frequency'] = len(df_dqr[df_dqr[row['Feature']]==row['Mode']])\n",
    "    row['Mode %'] = round(row['Mode Frequency']/row['Count']*100, 2)\n",
    "    mode_df = df_dqr[df_dqr[row['Feature']]!=row['Mode']]\n",
    "    row['2nd Mode'] = mode_df[row['Feature']].mode()[0]\n",
    "    row['2nd Mode Frequency'] = len(mode_df[mode_df[row['Feature']]==row['2nd Mode']])\n",
    "    row['2nd Mode %'] = round(row['2nd Mode Frequency']/row['Count']*100, 2)\n",
    "\n",
    "dqr_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "      <th>Count</th>\n",
       "      <th>% Missing</th>\n",
       "      <th>Cardinality</th>\n",
       "      <th>Min</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Median</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAMAGE_PROPERTY</td>\n",
       "      <td>Total property damage caused by tornado</td>\n",
       "      <td>12945</td>\n",
       "      <td>10.8</td>\n",
       "      <td>396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>2800000000.0</td>\n",
       "      <td>1861676.964079</td>\n",
       "      <td>41350119.300074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOR_AREA</td>\n",
       "      <td>Product of length and width of the tornado</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5109</td>\n",
       "      <td>0.01</td>\n",
       "      <td>21.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>694.25</td>\n",
       "      <td>107338.0</td>\n",
       "      <td>1286.188574</td>\n",
       "      <td>4379.919257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARM_TOTAL</td>\n",
       "      <td>Total injuries and deaths caused</td>\n",
       "      <td>14988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.859488</td>\n",
       "      <td>15.81549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature                                 Description  Count  \\\n",
       "0  DAMAGE_PROPERTY     Total property damage caused by tornado  12945   \n",
       "1         TOR_AREA  Product of length and width of the tornado  14988   \n",
       "2       HARM_TOTAL            Total injuries and deaths caused  14988   \n",
       "\n",
       "  % Missing Cardinality   Min    Q1   Median       Q3           Max  \\\n",
       "0      10.8         396   0.0   0.0  10000.0  80000.0  2800000000.0   \n",
       "1       0.0        5109  0.01  21.9    135.0   694.25      107338.0   \n",
       "2       0.0          82     0   0.0      0.0      0.0          1311   \n",
       "\n",
       "             Mean              STD  \n",
       "0  1861676.964079  41350119.300074  \n",
       "1     1286.188574      4379.919257  \n",
       "2        0.859488         15.81549  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqr_cont = pd.DataFrame(columns=['Feature', 'Description','Count','% Missing', 'Cardinality','Min','Q1','Median','Q3','Max','Mean','STD'])\n",
    "\n",
    "cont_cols = ['DAMAGE_PROPERTY', 'TOR_AREA', 'HARM_TOTAL']\n",
    "dqr_cont['Feature'] = cont_cols\n",
    "total_count = np.size(df_dqr)\n",
    "descs = ['Total property damage caused by tornado', 'Product of length and width of the tornado', 'Total injuries and deaths caused']\n",
    "\n",
    "for index, row in dqr_cont.iterrows():\n",
    "    row['Description'] = descs[index]\n",
    "    row['Count'] = df_dqr[row['Feature']].count()\n",
    "    if row['Feature'] == 'DAMAGE_PROPERTY':\n",
    "        row['% Missing'] = round(row['Count']/total_count * 100, 2)\n",
    "    else:\n",
    "        row['% Missing'] = round((len(df_dqr[df_dqr[row['Feature']]==None])/row['Count'])*100, 2)\n",
    "    row['Cardinality'] = len(df_dqr[row['Feature']].unique())\n",
    "    row['Min'] = df_dqr[row['Feature']].min()\n",
    "    row['Max'] = df_dqr[row['Feature']].max()\n",
    "    row['Q1'] = df_dqr[row['Feature']].quantile(0.25)\n",
    "    row['Q3'] = df_dqr[row['Feature']].quantile(0.75)\n",
    "    row['Median'] = df_dqr[row['Feature']].median()\n",
    "    row['Mean'] = df_dqr[row['Feature']].sum()/row['Count']\n",
    "    row['STD'] = df_dqr[row['Feature']].std()\n",
    "\n",
    "dqr_cont"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
