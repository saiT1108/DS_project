{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Read all data into one single dataframe\n",
    "df_all_data = pd.read_csv('./dataset/storm_event_details_2010.csv')\n",
    "\n",
    "for i in range(2011,2021):\n",
    "    df_temp = pd.read_csv(f'./dataset/storm_event_details_{i}.csv')\n",
    "    df_all_data = df_all_data.append(df_temp, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6632/2115226861.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n"
     ]
    }
   ],
   "source": [
    "## Remove unused columns and format continuous columns\n",
    "\n",
    "df_hur = df_all_data[df_all_data['EVENT_TYPE']=='Tornado']\n",
    "df_hur = df_hur.drop(columns=['TOR_OTHER_WFO', 'END_YEARMONTH', 'EVENT_TYPE', 'END_DATE_TIME',\n",
    "                                           'TOR_OTHER_CZ_STATE','TOR_OTHER_CZ_FIPS','TOR_OTHER_CZ_NAME','DATA_SOURCE','EPISODE_NARRATIVE',\n",
    "                                            'EVENT_NARRATIVE','WFO','SOURCE','CZ_TIMEZONE','BEGIN_AZIMUTH','END_AZIMUTH','BEGIN_LAT',\n",
    "                                            'END_LAT','BEGIN_LON','END_LON','STATE_FIPS','BEGIN_RANGE','END_RANGE','DAMAGE_CROPS',\n",
    "                                            'BEGIN_TIME','END_TIME','BEGIN_LOCATION','END_LOCATION','FLOOD_CAUSE','MAGNITUDE_TYPE',\n",
    "                                            'MAGNITUDE','CZ_FIPS','CZ_TYPE','CZ_NAME','CATEGORY'])\n",
    "cols = ['INJURIES_INDIRECT', 'INJURIES_DIRECT', 'DEATHS_INDIRECT', 'DEATHS_DIRECT']\n",
    "df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n",
    "df_hur['TOR_AREA'] = df_hur['TOR_LENGTH']*df_hur['TOR_WIDTH']\n",
    "df_hur = df_hur.drop(columns=['TOR_LENGTH', 'TOR_WIDTH'])\n",
    "df_hur = df_hur.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAMAGE_PROPERTY\n",
      "75               5.00K\n",
      "304              1.50M\n",
      "617             10.00K\n",
      "731            750.00K\n",
      "732             10.00K\n",
      "...                ...\n",
      "688471           0.00K\n",
      "688472         250.00K\n",
      "688495          60.00K\n",
      "688497           0.00K\n",
      "688560           0.00K\n",
      "\n",
      "[12945 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## Format DAMAGE_PROPERTY column to be float instead of object\n",
    "\n",
    "dmg = pd.DataFrame(df_hur['DAMAGE_PROPERTY'])\n",
    "\n",
    "print(dmg)\n",
    "for index, row in dmg.iterrows():\n",
    "    val = row['DAMAGE_PROPERTY']\n",
    "    if val[-1:] == 'B':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000\n",
    "        # print(float(row['DAMAGE_PROPERTY'][:-1])*1000000)\n",
    "    elif val[-1:] == 'M':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000\n",
    "        # print(float(row['DAMAGE_PROPERTY'][:-1])*1000)\n",
    "    elif val[-1:] == 'K':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1\n",
    "        # print(float(row['DAMAGE_PROPERTY'][:-1]))\n",
    "\n",
    "df_hur['DAMAGE_PROPERTY'] = dmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12945 entries, 100619 to 688560\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   BEGIN_YEARMONTH  12945 non-null  int64  \n",
      " 1   BEGIN_DAY        12945 non-null  int64  \n",
      " 2   END_DAY          12945 non-null  int64  \n",
      " 3   EPISODE_ID       12945 non-null  int64  \n",
      " 4   EVENT_ID         12945 non-null  int64  \n",
      " 5   STATE            12945 non-null  object \n",
      " 6   YEAR             12945 non-null  int64  \n",
      " 7   MONTH_NAME       12945 non-null  object \n",
      " 8   BEGIN_DATE_TIME  12945 non-null  object \n",
      " 9   DAMAGE_PROPERTY  12945 non-null  object \n",
      " 10  TOR_F_SCALE      12945 non-null  object \n",
      " 11  HARM_TOTAL       12945 non-null  int64  \n",
      " 12  TOR_AREA         12945 non-null  float64\n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 1.4+ MB\n",
      "EF0    51.117296\n",
      "EF1    35.737575\n",
      "EF2     9.852883\n",
      "EF3     2.576541\n",
      "EF4     0.628231\n",
      "EF5     0.087475\n",
      "Name: TOR_F_SCALE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Sort by priority variable and find data split percentages\n",
    "\n",
    "df_hur = df_hur.sort_values('DAMAGE_PROPERTY', ascending=False)\n",
    "df_hur.info()\n",
    "df_hur = df_hur.loc[df_hur['TOR_F_SCALE']!='EFU']\n",
    "print(df_hur['TOR_F_SCALE'].value_counts()/len(df_hur) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "April        21.677932\n",
       "May          20.548708\n",
       "June         12.413519\n",
       "July          7.093439\n",
       "March         6.727634\n",
       "August        6.067594\n",
       "October       5.137177\n",
       "November      4.580517\n",
       "January       4.413519\n",
       "February      4.159046\n",
       "September     3.618290\n",
       "December      3.562624\n",
       "Name: MONTH_NAME, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hur['MONTH_NAME'].value_counts()/len(df_hur) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>BEGIN_DATE_TIME</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>HARM_TOTAL</th>\n",
       "      <th>TOR_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54412</th>\n",
       "      <td>201009</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>43020</td>\n",
       "      <td>250744</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>2010</td>\n",
       "      <td>September</td>\n",
       "      <td>15-SEP-10 17:28:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93458</th>\n",
       "      <td>201104</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>51045</td>\n",
       "      <td>305053</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>28-APR-11 15:10:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>314.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59662</th>\n",
       "      <td>201006</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>39661</td>\n",
       "      <td>247446</td>\n",
       "      <td>SOUTH DAKOTA</td>\n",
       "      <td>2010</td>\n",
       "      <td>June</td>\n",
       "      <td>16-JUN-10 17:53:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617967</th>\n",
       "      <td>201912</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>144955</td>\n",
       "      <td>870503</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2019</td>\n",
       "      <td>December</td>\n",
       "      <td>16-DEC-19 15:45:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>156.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332528</th>\n",
       "      <td>201506</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>95142</td>\n",
       "      <td>571626</td>\n",
       "      <td>NEBRASKA</td>\n",
       "      <td>2015</td>\n",
       "      <td>June</td>\n",
       "      <td>14-JUN-15 11:25:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168814</th>\n",
       "      <td>201202</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>60247</td>\n",
       "      <td>359691</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>2012</td>\n",
       "      <td>February</td>\n",
       "      <td>29-FEB-12 04:51:00</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>103</td>\n",
       "      <td>5177.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105205</th>\n",
       "      <td>201104</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>50455</td>\n",
       "      <td>309071</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 15:35:00</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>49</td>\n",
       "      <td>30645.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104764</th>\n",
       "      <td>201104</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>50455</td>\n",
       "      <td>314886</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 17:32:00</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>43</td>\n",
       "      <td>50776.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244989</th>\n",
       "      <td>201302</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>71831</td>\n",
       "      <td>433413</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2013</td>\n",
       "      <td>February</td>\n",
       "      <td>10-FEB-13 17:03:00</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>8</td>\n",
       "      <td>9966.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126745</th>\n",
       "      <td>201104</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>50516</td>\n",
       "      <td>301811</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2011</td>\n",
       "      <td>April</td>\n",
       "      <td>27-APR-11 14:28:00</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>EF5</td>\n",
       "      <td>27</td>\n",
       "      <td>29832.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BEGIN_YEARMONTH  BEGIN_DAY  END_DAY  EPISODE_ID  EVENT_ID  \\\n",
       "54412            201009         15       15       43020    250744   \n",
       "93458            201104         28       28       51045    305053   \n",
       "59662            201006         16       16       39661    247446   \n",
       "617967           201912         16       16      144955    870503   \n",
       "332528           201506         14       14       95142    571626   \n",
       "...                 ...        ...      ...         ...       ...   \n",
       "168814           201202         29       29       60247    359691   \n",
       "105205           201104         27       27       50455    309071   \n",
       "104764           201104         27       27       50455    314886   \n",
       "244989           201302         10       10       71831    433413   \n",
       "126745           201104         27       27       50516    301811   \n",
       "\n",
       "                 STATE  YEAR MONTH_NAME     BEGIN_DATE_TIME DAMAGE_PROPERTY  \\\n",
       "54412           KANSAS  2010  September  15-SEP-10 17:28:00             0.0   \n",
       "93458   NORTH CAROLINA  2011      April  28-APR-11 15:10:00            33.0   \n",
       "59662     SOUTH DAKOTA  2010       June  16-JUN-10 17:53:00             0.0   \n",
       "617967     MISSISSIPPI  2019   December  16-DEC-19 15:45:00            10.0   \n",
       "332528        NEBRASKA  2015       June  14-JUN-15 11:25:00             0.0   \n",
       "...                ...   ...        ...                 ...             ...   \n",
       "168814        ILLINOIS  2012   February  29-FEB-12 04:51:00          2000.0   \n",
       "105205         ALABAMA  2011      April  27-APR-11 15:35:00        115000.0   \n",
       "104764         ALABAMA  2011      April  27-APR-11 17:32:00        200000.0   \n",
       "244989     MISSISSIPPI  2013   February  10-FEB-13 17:03:00         13500.0   \n",
       "126745         ALABAMA  2011      April  27-APR-11 14:28:00         50000.0   \n",
       "\n",
       "       TOR_F_SCALE  HARM_TOTAL  TOR_AREA  \n",
       "54412          EF0           0     30.00  \n",
       "93458          EF0           0    314.50  \n",
       "59662          EF0           0      1.50  \n",
       "617967         EF0           0    156.60  \n",
       "332528         EF0           0     26.00  \n",
       "...            ...         ...       ...  \n",
       "168814         EF4         103   5177.25  \n",
       "105205         EF4          49  30645.12  \n",
       "104764         EF4          43  50776.00  \n",
       "244989         EF4           8   9966.00  \n",
       "126745         EF5          27  29832.00  \n",
       "\n",
       "[1257 rows x 13 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split data into strata and sample proportinally (stratified sampling)\n",
    "\n",
    "sampled_df = df_hur.groupby('TOR_F_SCALE', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "sampled_df\n",
    "# sampled_df['MONTH_NAME'].value_counts()/len(df_hur) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
