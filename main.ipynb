{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severity of storms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our project will focus on analyzing and predicting the severity of tornadoes across various regions in America in terms of property damage. To analyze this, we will take the last 10 years of tornado data to represent an approximate measure of it. To calculate this, we will establish a threshold for measuring the severity using the amount of property damage caused by tornadoes. We will predict the property damage of tornadoes and use a scale of low, medium, and high to represent the severity.  \n",
    "In addition, we will also compare attitudes across each of the 4 seasons - summer, spring, winter, fall, and see if there are any trends present across the 10 year span that shows when tornadoes are most common and damaging. The trends will help us be more accurate in predicting the property damage caused by the tornadoes  per region during different seasons/times of the year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our dataset details instances of severe weather across a 15 year period. We will be looking at Tornados across this time period. We are given the locations that the Tornados are in, the category of Tornadoes, fatalities, property damage, and the length of the storm. From this we created a target feature called severity which assigns tornados a number from 1 to 10 based on how severe they are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Proposed analytics solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " How we get to the target variable -- severity index\n",
    "The severity index will be calculated by taking into account the property damage, the lives lost in the event, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Read all data into one single dataframe\n",
    "df_all_data = pd.read_csv('./dataset/storm_event_details_2010.csv')\n",
    "\n",
    "\n",
    "for i in range(2011,2021):\n",
    "    df_temp = pd.read_csv(f'./dataset/storm_event_details_{i}.csv')\n",
    "    df_all_data = df_all_data.append(df_temp, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/t1n97j495rq26g0zhqy_3ty80000gn/T/ipykernel_20737/2115226861.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n"
     ]
    }
   ],
   "source": [
    "## Remove unused columns and format continuous columns\n",
    "\n",
    "df_hur = df_all_data[df_all_data['EVENT_TYPE']=='Tornado']\n",
    "df_hur = df_hur.drop(columns=['TOR_OTHER_WFO', 'END_YEARMONTH', 'EVENT_TYPE', 'END_DATE_TIME',\n",
    "                                           'TOR_OTHER_CZ_STATE','TOR_OTHER_CZ_FIPS','TOR_OTHER_CZ_NAME','DATA_SOURCE','EPISODE_NARRATIVE',\n",
    "                                            'EVENT_NARRATIVE','WFO','SOURCE','CZ_TIMEZONE','BEGIN_AZIMUTH','END_AZIMUTH','BEGIN_LAT',\n",
    "                                            'END_LAT','BEGIN_LON','END_LON','STATE_FIPS','BEGIN_RANGE','END_RANGE','DAMAGE_CROPS',\n",
    "                                            'BEGIN_TIME','END_TIME','BEGIN_LOCATION','END_LOCATION','FLOOD_CAUSE','MAGNITUDE_TYPE',\n",
    "                                            'MAGNITUDE','CZ_FIPS','CZ_TYPE','CZ_NAME','CATEGORY'])\n",
    "cols = ['INJURIES_INDIRECT', 'INJURIES_DIRECT', 'DEATHS_INDIRECT', 'DEATHS_DIRECT']\n",
    "df_hur = df_hur.assign(HARM_TOTAL=df_hur[cols].sum(1)).drop(cols,1)\n",
    "df_hur['TOR_AREA'] = df_hur['TOR_LENGTH']*df_hur['TOR_WIDTH']\n",
    "df_hur = df_hur.drop(columns=['TOR_LENGTH', 'TOR_WIDTH'])\n",
    "df_hur = df_hur.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAMAGE_PROPERTY\n",
      "75               5.00K\n",
      "304              1.50M\n",
      "617             10.00K\n",
      "731            750.00K\n",
      "732             10.00K\n",
      "...                ...\n",
      "688471           0.00K\n",
      "688472         250.00K\n",
      "688495          60.00K\n",
      "688497           0.00K\n",
      "688560           0.00K\n",
      "\n",
      "[12945 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## Format DAMAGE_PROPERTY column to be float instead of object\n",
    "\n",
    "dmg = pd.DataFrame(df_hur['DAMAGE_PROPERTY'])\n",
    "\n",
    "print(dmg)\n",
    "for index, row in dmg.iterrows():\n",
    "    val = row['DAMAGE_PROPERTY']\n",
    "    if val[-1:] == 'B':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000000\n",
    "        # print(float(row['DAMAGE_PROPERTY'][:-1])*1000000)\n",
    "    elif val[-1:] == 'M':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1000\n",
    "        # print(float(row['DAMAGE_PROPERTY'][:-1])*1000)\n",
    "    elif val[-1:] == 'K':\n",
    "        row['DAMAGE_PROPERTY'] = float(val[:-1])*1\n",
    "        # print(float(row['DAMAGE_PROPERTY'][:-1]))\n",
    "\n",
    "df_hur['DAMAGE_PROPERTY'] = dmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12945 entries, 100619 to 688560\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   BEGIN_YEARMONTH  12945 non-null  int64  \n",
      " 1   BEGIN_DAY        12945 non-null  int64  \n",
      " 2   END_DAY          12945 non-null  int64  \n",
      " 3   EPISODE_ID       12945 non-null  int64  \n",
      " 4   EVENT_ID         12945 non-null  int64  \n",
      " 5   STATE            12945 non-null  object \n",
      " 6   YEAR             12945 non-null  int64  \n",
      " 7   MONTH_NAME       12945 non-null  object \n",
      " 8   BEGIN_DATE_TIME  12945 non-null  object \n",
      " 9   DAMAGE_PROPERTY  12945 non-null  object \n",
      " 10  TOR_F_SCALE      12945 non-null  object \n",
      " 11  HARM_TOTAL       12945 non-null  int64  \n",
      " 12  TOR_AREA         12945 non-null  float64\n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 1.4+ MB\n",
      "EF0    51.117296\n",
      "EF1    35.737575\n",
      "EF2     9.852883\n",
      "EF3     2.576541\n",
      "EF4     0.628231\n",
      "EF5     0.087475\n",
      "Name: TOR_F_SCALE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Sort by priority variable and find data split percentages\n",
    "\n",
    "df_hur = df_hur.sort_values('DAMAGE_PROPERTY', ascending=False)\n",
    "df_hur.info()\n",
    "df_hur = df_hur.loc[df_hur['TOR_F_SCALE']!='EFU']\n",
    "print(df_hur['TOR_F_SCALE'].value_counts()/len(df_hur) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "April        21.677932\n",
       "May          20.548708\n",
       "June         12.413519\n",
       "July          7.093439\n",
       "March         6.727634\n",
       "August        6.067594\n",
       "October       5.137177\n",
       "November      4.580517\n",
       "January       4.413519\n",
       "February      4.159046\n",
       "September     3.618290\n",
       "December      3.562624\n",
       "Name: MONTH_NAME, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hur['MONTH_NAME'].value_counts()/len(df_hur) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH_NAME</th>\n",
       "      <th>BEGIN_DATE_TIME</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>HARM_TOTAL</th>\n",
       "      <th>TOR_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455382</th>\n",
       "      <td>201705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116614</td>\n",
       "      <td>701343</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>May</td>\n",
       "      <td>01-MAY-17 09:24:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530870</th>\n",
       "      <td>201808</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>128692</td>\n",
       "      <td>771917</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>2018</td>\n",
       "      <td>August</td>\n",
       "      <td>28-AUG-18 15:33:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513393</th>\n",
       "      <td>201804</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>124296</td>\n",
       "      <td>748357</td>\n",
       "      <td>LOUISIANA</td>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>14-APR-18 02:36:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460629</th>\n",
       "      <td>201702</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>113282</td>\n",
       "      <td>678847</td>\n",
       "      <td>KENTUCKY</td>\n",
       "      <td>2017</td>\n",
       "      <td>February</td>\n",
       "      <td>28-FEB-17 22:35:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47739</th>\n",
       "      <td>201006</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>42657</td>\n",
       "      <td>248773</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2010</td>\n",
       "      <td>June</td>\n",
       "      <td>30-JUN-10 13:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170153</th>\n",
       "      <td>201203</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60205</td>\n",
       "      <td>359912</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>2012</td>\n",
       "      <td>March</td>\n",
       "      <td>02-MAR-12 15:09:00</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>1</td>\n",
       "      <td>11697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662554</th>\n",
       "      <td>202007</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>148227</td>\n",
       "      <td>898306</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>2020</td>\n",
       "      <td>July</td>\n",
       "      <td>08-JUL-20 16:08:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>0</td>\n",
       "      <td>1534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344213</th>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>101364</td>\n",
       "      <td>606471</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2015</td>\n",
       "      <td>December</td>\n",
       "      <td>26-DEC-15 18:46:00</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>478</td>\n",
       "      <td>5065.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35891</th>\n",
       "      <td>201004</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>38376</td>\n",
       "      <td>224552</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>2010</td>\n",
       "      <td>April</td>\n",
       "      <td>24-APR-10 11:33:00</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>EF4</td>\n",
       "      <td>41</td>\n",
       "      <td>55250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265662</th>\n",
       "      <td>201305</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>74673</td>\n",
       "      <td>451572</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>2013</td>\n",
       "      <td>May</td>\n",
       "      <td>20-MAY-13 14:04:00</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>EF5</td>\n",
       "      <td>231</td>\n",
       "      <td>22800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BEGIN_YEARMONTH  BEGIN_DAY  END_DAY  EPISODE_ID  EVENT_ID  \\\n",
       "455382           201705          1        1      116614    701343   \n",
       "530870           201808         28       28      128692    771917   \n",
       "513393           201804         14       14      124296    748357   \n",
       "460629           201702         28       28      113282    678847   \n",
       "47739            201006         30       30       42657    248773   \n",
       "...                 ...        ...      ...         ...       ...   \n",
       "170153           201203          2        2       60205    359912   \n",
       "662554           202007          8        8      148227    898306   \n",
       "344213           201512         26       26      101364    606471   \n",
       "35891            201004         24       24       38376    224552   \n",
       "265662           201305         20       20       74673    451572   \n",
       "\n",
       "              STATE  YEAR MONTH_NAME     BEGIN_DATE_TIME DAMAGE_PROPERTY  \\\n",
       "455382      GEORGIA  2017        May  01-MAY-17 09:24:00            25.0   \n",
       "530870    WISCONSIN  2018     August  28-AUG-18 15:33:00             0.0   \n",
       "513393    LOUISIANA  2018      April  14-APR-18 02:36:00            50.0   \n",
       "460629     KENTUCKY  2017   February  28-FEB-17 22:35:00            35.0   \n",
       "47739         TEXAS  2010       June  30-JUN-10 13:30:00             0.0   \n",
       "...             ...   ...        ...                 ...             ...   \n",
       "170153      INDIANA  2012      March  02-MAR-12 15:09:00         55000.0   \n",
       "662554    MINNESOTA  2020       July  08-JUL-20 16:08:00           100.0   \n",
       "344213        TEXAS  2015   December  26-DEC-15 18:46:00         26000.0   \n",
       "35891   MISSISSIPPI  2010      April  24-APR-10 11:33:00         60000.0   \n",
       "265662     OKLAHOMA  2013        May  20-MAY-13 14:04:00       2000000.0   \n",
       "\n",
       "       TOR_F_SCALE  HARM_TOTAL  TOR_AREA  \n",
       "455382         EF0           0     354.0  \n",
       "530870         EF0           0       0.5  \n",
       "513393         EF0           0     884.0  \n",
       "460629         EF0           0     121.8  \n",
       "47739          EF0           0       4.2  \n",
       "...            ...         ...       ...  \n",
       "170153         EF4           1   11697.0  \n",
       "662554         EF4           0    1534.0  \n",
       "344213         EF4         478    5065.5  \n",
       "35891          EF4          41   55250.0  \n",
       "265662         EF5         231   22800.0  \n",
       "\n",
       "[1257 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split data into strata and sample proportinally (stratified sampling)\n",
    "\n",
    "sampled_df = df_hur.groupby('TOR_F_SCALE', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "sampled_df\n",
    "# sampled_df['MONTH_NAME'].value_counts()/len(df_hur) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize damage property \n",
    "#visualize tornado area "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data Quality Report for Continuous Variables\n",
    "| Feature | Desc. | Count | % of Missing | Card. | Min. | Q1 | Median | Q3 | Max. | Mean | Std. Dev. | Notes |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| AAGE | Age | 199,523 | 0 | 91 | 0 | 15 | 33 | 50 | 90 | 34.49 | 22.31 |  |\n",
    "\n",
    "### Example Data Quality Report for Categorical Variables\n",
    "| Feature | Desc. | Count | % of Missing | Card. | Mode | Mode Freq. | Mode % | 2nd Mode | 2nd Mode Freq. | 2nd Mode Perc | Notes |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| ACLSWKR | Class of worker | 199,523 | 0 | 9 | Not in Universe | 100,245 | 50.24 | Private | 72,028 |  36.10 |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For missing values we will be dropping the instances because we will be taking a 10% sample of the instances. for outliers if its skewed then the outliers are more important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what we need to normalize and how we will normalize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
